# Gait-Recognition

### Dataset ###
CASIA -B dataset -> A large multiview gait database. There are 124 subjects, and the gait data was captured from 11 views with three variations, namely view angle, clothing and carrying condition changes, separately considered. All the videos are of different length.

### Problem Statement ###
Gait (walking style)  is a soft biometric. The purpose is to recognize people by their gait data.

### Solution ###
Two attention based architectures are implemented inspired from Video Vision Transformer. 


### * Architecture 1: Factorized encoder * ###
<img src ="https://github.com/Shivani-15/Gait-Recognition/assets/58560161/1f83d35a-a46f-409b-9c5d-d2a70b0c95fd" width= 300 height = 400>
<br>
<br>
### * Architecture 2: Factorized self-attention * ###
<img src = "https://github.com/Shivani-15/Gait-Recognition/assets/58560161/7d73a6a7-0808-4c8c-beed-8dab2dd268ee" width= 300 height = 400>)

